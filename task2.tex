\documentclass[a4paper,12pt,twoside]{article}
\pagestyle{headings}
\usepackage{a4wide}
\usepackage{mathtools}
\usepackage[colorlinks,hyperfigures,backref,bookmarks,draft=false]{hyperref}

\title{stance detection\\ Web Science }

\author{*}

\begin{document}
\maketitle
\section{Introduction}
Stance detection means to determine the viewpoint on a certain topic, person, organisation or similar based on a natural-language based medium like text.\\ 
To create such a stance detector a system needs to be trained with the help of a training set containing already predeterminded stances and the corresponding weighting. While considering the probability of word combinations in the training set predictions for the test set can be made.\\
In contrast to sentiment analysis the stance towards a topic is exermined even when the target does not explicitely occur in the test medium. \\
Stance detectors find for example use in the area of web data analysis to detect the stances of users to obtain an overview of the trends in the word wide web. \\
The here implemented stance detector is working with tweets for the topics : Atheism, Legalization of Abortion, Climate Change is a real Concern, Feminist Movement, Hillary Clinton. Therefore the stances favor, against and neutral were applied.\\
The used data set originates to the SemEval-2016 Shared Task on Stance Detection in Tweets
(Mohammad et al. 2016) \url{http://alt.qcri.org/semeval2016/task6/}.



\section{Methodology}
The training set has been tokenized with the tokenisation algorithm than stopwords and tokens of the length of 1 were removed. \\
The examined features for the classification are bigrams consisting of 2 consecutive tokens. So except for the first and the last token, each token is part of 2 bigrams.\\
A vocabulary over all occuring tokens were constructed. In the following for each tweet a vector was created containing the amount of the associated bigrams.\\
The classifier was trained using these vectors and the known stances. Herefore the Nearest Centroid classifier was chosen. It decides the affiliation of a vector in the context of multiple vector groups by creating vector centroids for each stance and classifying a new vector by determining the nearest centroid.\\
This classifier was applied to the test data, which had been equaly tokenized as the training data. It is essential to mention that the vectorisation used the vocabulary of the training set. Bigramms not included in the training set vocabulary were not counted and have no effect on the classification. Using a bigger training set would reduce this shortage. \\
The classified stances can be evaluated by comparing them with the known stances. For this evaluation the F1 score was used. For that reason the true positives (TP), false positives (FP) and false negatives (FN) were counted.
\begin{equation}
F_1 = \frac{2*TP}{ 2*TP + FP + FN}
\end{equation}
The F1 score allows an estimation of the precision and recall of the trained classifier. When both are optimal the F1 score approaches 1.

\section{About the Implementation}
The stance detector was implemented in Python. The data files were read using pandas. The test and training tweets were tokenized with the use of the library nltk tweet tokenizer. Furtheron stopwords were removed with the help of the nltk stopword list.
Tokens of the length of 1 have been deleted due to resulting improvements of the F1 Score. \\
The Nearest Centroid Classifier  of the sklearn package was chosen to classify the test and training vectors.
for each class calculation of centroid by considering vector positions of all members.
New vector is classified to the nearest centroid. Prediction possible

\section{Findings}

In the following the results for the F1 score as the amount of true positive (TP), false positive (FP) and false negative (FN) predictions are shown. The topics "Atheism" and "Climate Change is a real Concern" have been chosen for further examination.\\
\\
\textbf{Atheism}\\
\\
\begin{tabular}{c|ccc|c}
stance & TP & FP & FN & F1\\ \hline
Favor & 2 & 0 & 30 & 0.11764705882352941\\
Against & 154 & 0 & 6 & 0.9808917197452229 \\
Neutral & 0 & 0 & 28 & 0.0 \\
\end{tabular}\\
\\
\textbf{Climate Change is a real Concern} \\
\\
\begin{tabular}{c|ccc|c}
stance & TP & FP & FN & F1\\ \hline
Favor & 42 & 0 & 81 & 0.509090909090909\\
Against & 0 & 0 & 11 & 0.0\\
Neutral & 35 & 0 & 0 & 1.0 \\
\end{tabular}\\
\\
One can observe that the F1 score of each topic is very high (1.0). For example the against score of the topic "Atheism" or the neutral score in the topic "Climate Change is a Real Concern". The other stance scores are lower or 0, which means a bad prediction rate for these stances.\\
These results correlate with the structure of the training set. When examining the training set a low diversity is present.\\

\begin{tabular}{c|ccc}
& favor & against & neutral\\ \hline
Climate Change is a Real Concern & 123 & 11 & 35 \\
Atheism & 32 & 160 & 28 \\
\end{tabular} \\
\\
This low diversity leads to a low F1 score because the classifier has to be trained with sufficient examples to give sufficient predictions.\\
Furtheron the classifier was tested otherwise. When using the training set as training and test set the classifier has to classify the tweets he trained on. Hence the F1 score should be higher.
Here the classifier was used on the topic "Atheism", which led to the following results. \\
\\
\textbf{Atheism}
\\
\begin{tabular}{c|ccc|c}
stance & TP & FP & FN & F1\\ \hline
Favor & 91 & 0 & 1 & 0.994535\\
Against & 117 & 0 & 0 & 1.0\\
Neutral &  303 & 0 & 1 & 0.998353\\
\end{tabular}\\
\\
As expected very high F1 score. Nonetheless 2 faults could be found for the following tweets:\\
\em{FAVOR: god of the gaps is not evidence \# next \# SemST}\\
\em{AGAINST: I hope no one is hurt. \# WhoIsBurningBlackChurches \# EndRacism \# LoveWins \# SemST}\\
Even for a human these tweets might be difficult to classify. They indicate the problem with emotional background, irony and tonation of stance detector systems. 

\section{Discussion}

depends on treatment of unknown bigrams which are not in training vocabulary -> not counted .> more vectors near to origin (null vector) ->classification by nearest centroid: atheism: against, Climate change is a real concern: Neutral
Bigger vocabulary solves this problem, no classification of unknown bigrams


It is observable that in both 

- use of better training data wih higher variability to teach classifier all possible aspects of a stance
- only use of familiar bigrams limits performance
- addition of bigrams to vocabulary heavy
- size of matrix containing so many zeros



\section{Conclusion}



\bibliographystyle{alpha}
\bibliography{task2.bib} 
\end{document}
